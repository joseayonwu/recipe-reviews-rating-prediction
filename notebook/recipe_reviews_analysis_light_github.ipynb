{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8fc48e",
   "metadata": {},
   "source": [
    "# Recipe Reviews — Predicting Star Ratings (1–5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072870a",
   "metadata": {},
   "source": [
    "## Author: Jose Antonio Ayon Wu  \n",
    "Master’s in Data Analytics, University of Niagara Falls (UNF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e48ff",
   "metadata": {},
   "source": [
    "## Project Overview & Executive Summary\n",
    "\n",
    "**Goal.** Predict the exact star rating (1–5) for recipe reviews using `recipe_reviews.csv`, and explain which factors drive those predictions.\n",
    "\n",
    "**Plan.** I’m keeping the workflow simple and reproducible: (1) load and clean the data, (2) quick EDA (distributions and correlations), (3) light feature engineering (e.g., log scales, text counts, categorical encoding), and (4) two models—Logistic Regression and Random Forest—with a small grid search. I evaluate with accuracy, precision/recall/F1, and AUC, plus confusion matrices and a short side-by-side comparison. Key figures are also exported as PNGs so the submission includes both the notebook and the visuals.\n",
    "\n",
    "**What to expect.** Ratings are somewhat imbalanced (more 4–5s), so the middle classes will be trickier. I’ll call that out in the results and highlight which features matter most, along with a few practical takeaways and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61627ff",
   "metadata": {},
   "source": [
    "## Block 1 – Data Loading & Initial Checks\n",
    "\n",
    "**Goal of this section:**  \n",
    "Load the dataset, check its structure, review missing values and duplicates, and confirm the **target column** (`stars`) for prediction.\n",
    "\n",
    "**Notes:**  \n",
    "- Several score-like columns exist (`likes_score`, `score_log`, `ranking_score`, etc.). These are features derived from user interactions, but **not the prediction target**.\n",
    "- The true label is the **`stars` column**, representing recipe ratings from 0 to 5.\n",
    "- This section only inspects the data—**no cleaning or transformation** is performed here. Data cleaning will be handled in the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Part 4 — Block 1: Data Loading & Initial Checks\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/recipe_reviews.csv\")\n",
    "print(\"[OK] Dataset loaded successfully\")\n",
    "print(\"Shape (rows, columns):\", df.shape)\n",
    "\n",
    "# Quick preview\n",
    "print(\"\\n[Head] First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Column list and info\n",
    "print(\"\\n[Columns] List of columns:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "print(\"\\n[Info] Dataset summary:\")\n",
    "df.info()\n",
    "\n",
    "# Missing values\n",
    "na_counts = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\n[Missing values] Top 8 columns:\")\n",
    "display(na_counts.head(8))\n",
    "\n",
    "# Bar plot of missing values (Top 6)\n",
    "top_missing = na_counts.head(6)\n",
    "\n",
    "if top_missing.sum() > 0:\n",
    "    colors = ['salmon' if col == 'text' else 'lightblue' for col in top_missing.index]\n",
    "\n",
    "    ax = top_missing.plot(kind=\"bar\", color=colors)\n",
    "    plt.title(\"Top 6 Columns by Missing Values\")\n",
    "    plt.ylabel(\"Number of NaN\")\n",
    "    plt.xlabel(\"Column\")\n",
    "\n",
    "    # Force integer ticks on Y axis\n",
    "    import matplotlib.ticker as ticker\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/missing_values_barplot.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "# Target column = stars\n",
    "rating_col = \"stars\"\n",
    "\n",
    "print(f\"\\n[Target Column] Preview of '{rating_col}' distribution (raw values):\")\n",
    "display(df[rating_col].value_counts(dropna=False).sort_index())\n",
    "\n",
    "ax = df[rating_col].value_counts().sort_index().plot(\n",
    "    kind=\"bar\", \n",
    "    color=\"skyblue\", \n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "plt.title(\"Distribution of Star Ratings (Raw Data)\", fontsize=14)\n",
    "plt.xlabel(\"Star Rating\", fontsize=12)\n",
    "plt.ylabel(\"Number of Reviews\", fontsize=12)\n",
    "plt.savefig(\"outputs/stars_distribution_raw.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1) \n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add values on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type=\"edge\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Duplicates\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"\\n[Duplicates] Full-row duplicates detected: {dup_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b896c41",
   "metadata": {},
   "source": [
    "## Block 2 – Data Cleaning\n",
    "\n",
    "**From the instructions (Part 4 – Comprehensive Case Study):**  \n",
    "- *“Prepare the dataset for analysis by resolving common data quality issues.”*  \n",
    "- *“Identify and handle missing values. In this dataset, the value '2' is sometimes used as a placeholder for missing data.”*  \n",
    "- *“Remove or review duplicates and inconsistencies.”*  \n",
    "- *“Ensure correct data types.”*  \n",
    "- *“Normalize inconsistent categorical values.”*\n",
    "\n",
    "**Steps in this section:**  \n",
    "1. Handle missing values (including placeholders `'2'`).  \n",
    "2. Drop rows with missing `text` (only 2 cases).  \n",
    "3. Remove duplicates.  \n",
    "4. Drop irrelevant identifier columns (`Unnamed: 0`, `comment_id`, `user_id`, `user_name`).  \n",
    "5. Convert `created_at` into datetime format.  \n",
    "6. Normalize categorical values (`region`, `device_type`).  \n",
    "7. Verify distribution of target column (`stars`) after cleaning.\n",
    "\n",
    "The goal is to leave the dataset **clean and ready for Exploratory Data Analysis (EDA)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad792730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Part 4 — Block 2: Data Cleaning\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Handle missing values\n",
    "# -----------------------------\n",
    "print(\"\\n[Missing BEFORE cleaning]\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(8))\n",
    "\n",
    "# replace placeholder \"2\" in text-like columns (object/string, excluding IDs)\n",
    "obj_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "text_like_cols = [c for c in obj_cols if c not in [\"comment_id\", \"user_id\", \"user_name\"]]\n",
    "\n",
    "for col in text_like_cols:\n",
    "    df[col] = df[col].replace(\"2\", np.nan).replace(\"\", np.nan)\n",
    "\n",
    "print(\"\\n[Missing AFTER replacing placeholders]\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(8))\n",
    "\n",
    "# drop rows where text is missing (only 2 rows)\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "print(\"\\nDropped rows with missing 'text'. New shape:\", df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Remove duplicates\n",
    "# -----------------------------\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"\\n[Duplicates BEFORE] Full-row duplicates: {dup_count}\")\n",
    "df = df.drop_duplicates()\n",
    "print(\"[Duplicates AFTER] Shape:\", df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Drop irrelevant identifier columns\n",
    "# -----------------------------\n",
    "drop_cols = [\"Unnamed: 0\", \"comment_id\", \"user_id\", \"user_name\"]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "print(\"\\nDropped identifier columns:\", drop_cols)\n",
    "print(\"Current columns:\", list(df.columns))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fix data types\n",
    "# -----------------------------\n",
    "# created_at as datetime\n",
    "if \"created_at\" in df.columns:\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "# ensure stars is integer and valid (0–5)\n",
    "df[\"stars\"] = pd.to_numeric(df[\"stars\"], errors=\"coerce\")\n",
    "df = df[df[\"stars\"].isin([0,1,2,3,4,5])]\n",
    "print(\"\\n[Check] Unique values in stars:\", sorted(df[\"stars\"].unique()))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Normalize categorical values\n",
    "# -----------------------------\n",
    "for col in [\"region\", \"device_type\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.strip().str.lower()\n",
    "\n",
    "print(\"\\n[Preview] Unique values in region (normalized):\")\n",
    "if \"region\" in df.columns:\n",
    "    print(df[\"region\"].unique()[:10])  # show first 10 unique values\n",
    "\n",
    "print(\"\\n[Preview] Unique values in device_type (normalized):\")\n",
    "if \"device_type\" in df.columns:\n",
    "    print(df[\"device_type\"].unique())\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Verify target distribution\n",
    "# -----------------------------\n",
    "print(\"\\n[Stars distribution AFTER cleaning]\")\n",
    "print(df[\"stars\"].value_counts().sort_index())\n",
    "\n",
    "counts = df[\"stars\"].value_counts().sort_index()\n",
    "\n",
    "ax = counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Star Ratings after Data Cleaning\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add labels on top of bars\n",
    "for i, v in enumerate(counts):\n",
    "    plt.text(i, v + 100, str(v), ha=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/stars_distribution_cleaned.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee260e6",
   "metadata": {},
   "source": [
    "## Block 3 – Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Notes**  \n",
    "- In this block I perform Exploratory Data Analysis (EDA) to understand the structure of the dataset.  \n",
    "- I include distributions of numeric and categorical variables, relation between features and the target (`stars`), and correlations.  \n",
    "- The goal is not only to show plots but also to extract insights that will guide Feature Engineering and Model Building.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Block 3 – Exploratory Data Analysis (EDA)\n",
    "# =============================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "# ------------------------------\n",
    "# 0) Columns and helpers\n",
    "# ------------------------------\n",
    "num_cols = [\"recipe_number\", \"recipe_code\", \"likes_score\",\n",
    "            \"dislike_index\", \"response_level\", \"user_index\"]\n",
    "cat_cols = [\"region\", \"device_type\"]\n",
    "target = \"stars\"\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Distributions of numeric features (grouped) – Histogram + KDE\n",
    "# ------------------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 9))\n",
    "fig.suptitle(\"Distributions of Numeric Features (Histogram + KDE)\", fontsize=14)\n",
    "\n",
    "BINS = 30  # consistent binning across charts\n",
    "\n",
    "for ax, col in zip(axes.flatten(), num_cols):\n",
    "    sns.histplot(\n",
    "        data=df, x=col,\n",
    "        bins=BINS, kde=True,\n",
    "        color=\"blue\", edgecolor=\"black\",\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"Distribution of {col.replace('_',' ').title()}\", fontsize=11)\n",
    "    ax.set_xlabel(col.replace(\"_\",\" \").title())\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(\"outputs/numeric_distributions.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Distributions of categorical features (grouped)\n",
    "# ------------------------------\n",
    "fig, axes = plt.subplots(1, len(cat_cols), figsize=(12, 4))\n",
    "if len(cat_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, col in zip(axes, cat_cols):\n",
    "    order = df[col].value_counts().index\n",
    "    sns.countplot(x=col, data=df, order=order,\n",
    "                  color=\"skyblue\", edgecolor=\"black\", ax=ax)\n",
    "    ax.set_title(f\"Distribution of {col}\", fontsize=11)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "    # Labels on each bar\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/categorical_distributions.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Numeric features vs target (boxplots with outliers)\n",
    "# ------------------------------\n",
    "pair_cols = [\"recipe_number\", \"recipe_code\", \"likes_score\", \"dislike_index\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(pair_cols):\n",
    "    sns.boxplot(\n",
    "        x=target, y=col, data=df,\n",
    "        showfliers=True,   # keep outliers visible\n",
    "        width=0.6, ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"{col.replace('_',' ').title()} by Star Rating (with Outliers)\", fontsize=11)\n",
    "    axes[i].set_xlabel(\"Stars\")\n",
    "    axes[i].set_ylabel(col.replace(\"_\",\" \").title())\n",
    "    axes[i].grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "    axes[i].xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/numeric_vs_stars_boxplots.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Target by categorical variables (grouped countplots)\n",
    "# ------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.countplot(x=target, hue=\"region\", data=df, edgecolor=\"black\", ax=axes[0])\n",
    "axes[0].set_title(\"Star Ratings by Region\", fontsize=11)\n",
    "axes[0].set_xlabel(\"Stars\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].legend(title=\"region\")\n",
    "axes[0].grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "axes[0].xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "sns.countplot(x=target, hue=\"device_type\", data=df, edgecolor=\"black\", ax=axes[1])\n",
    "axes[1].set_title(\"Star Ratings by Device Type\", fontsize=11)\n",
    "axes[1].set_xlabel(\"Stars\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].legend(title=\"device_type\")\n",
    "axes[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "axes[1].xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/categorical_vs_stars_countplots.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Correlation heatmap (numeric only)\n",
    "# ------------------------------\n",
    "plt.figure(figsize=(10, 7))\n",
    "corr = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr, fmt='.2f', annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Heatmap of Numeric Features\", fontsize=12)\n",
    "plt.savefig(\"outputs/correlation_heatmap.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# 6) Quick descriptive statistics\n",
    "# ------------------------------\n",
    "print(\"\\n[Summary Statistics of numeric features]\")\n",
    "display(df.describe(include=[np.number]).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606cec0",
   "metadata": {},
   "source": [
    "### Observations – Block 3 (EDA)\n",
    "\n",
    "The dataset shows a very strong class imbalance, with most reviews concentrated in 5 stars.  \n",
    "This imbalance is likely to dominate model predictions unless addressed in later steps.  \n",
    "\n",
    "Continuous features such as `likes_score` and `dislike_index` display heavy right skewness, confirmed by KDE curves, suggesting that log transformations may help stabilize their scale.  \n",
    "Boxplots with outliers highlight that extreme values appear mainly in likes- and dislikes-related variables.  \n",
    "\n",
    "Categorical variables like `region` and `device_type` reveal broadly similar patterns, although imbalance persists within subgroups.  \n",
    "Finally, the correlation heatmap suggests redundancy (e.g., `ranking_value` vs `ranking_score`), which motivates pruning during feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1be92",
   "metadata": {},
   "source": [
    "## Block 4 – Feature Engineering\n",
    "\n",
    "**From the instructions:**  \n",
    "- *“Perform feature engineering to improve model performance. Create new variables, transformations, and encode categorical features.”*\n",
    "\n",
    "**Rationale from EDA results:**  \n",
    "- Numeric features are **highly right-skewed** (`likes_score`, `dislike_index`, etc.) → use `log1p`.  \n",
    "- We detected **near-duplicate information** (r ≈ 0.99):  \n",
    "  - (`likes_score` ↔ `likes`), (`dislike_index` ↔ `dislikes`), (`response_level` ↔ `responses`),  \n",
    "    (`user_index` ↔ `user_score`), (`ranking_value` ↔ `ranking_score`), (`text_len` ↔ `word_count`).  \n",
    "  - To **avoid multicollinearity** and keep the model simple, we will **keep one representative per par**.  \n",
    "- Categorical features (`region`, `device_type`) look balanced → one-hot encoding is appropriate.  \n",
    "- We keep the analysis **within course scope** (pandas / matplotlib / seaborn). No NLP avanzado.\n",
    "\n",
    "**Steps**  \n",
    "1) Text features (length and word count).  \n",
    "2) Log-transform of skewed metrics.  \n",
    "3) One-hot encoding for `region`, `device_type`.  \n",
    "4) **Prune** highly correlated / redundant columns (keep one per pair).  \n",
    "5) Build the **final modeling dataset** (`df_model`) and short sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Block 4 – Feature Engineering\n",
    "# ==============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "# Start from the cleaned df (from Block 2)\n",
    "data = df.copy()\n",
    "\n",
    "# ---------------------------------\n",
    "# 1) Simple text-derived features\n",
    "# ---------------------------------\n",
    "data[\"text_len\"]    = data[\"text\"].astype(str).apply(len)\n",
    "data[\"word_count\"]  = data[\"text\"].astype(str).apply(lambda x: len(x.split()))\n",
    "data[\"exclam_cnt\"]  = data[\"text\"].astype(str).str.count(\"!\")  # simple signal, still in course scope\n",
    "\n",
    "print(\"\\n[Preview] New text features:\")\n",
    "display(data[[\"text\", \"text_len\", \"word_count\", \"exclam_cnt\"]].head())\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(data[\"word_count\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of word_count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/word_count_distribution.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------\n",
    "# 2) Log transform for skewed vars\n",
    "# ---------------------------------\n",
    "# We clip at 0 to avoid log of negatives; this is acceptable for these usage indices.\n",
    "for col in [\"likes_score\", \"dislike_index\"]:\n",
    "    data[col + \"_log\"] = np.log1p(data[col].clip(lower=0))\n",
    "\n",
    "# quick before/after for likes_score\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "sns.histplot(data[\"likes_score\"], bins=30, kde=True, ax=ax[0], color=\"red\")\n",
    "ax[0].set_title(\"Original likes_score\")\n",
    "sns.histplot(data[\"likes_score_log\"], bins=30, kde=True, ax=ax[1], color=\"green\")\n",
    "ax[1].set_title(\"Log-transformed likes_score\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/likes_score_log_transformation.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------\n",
    "# 3) One-hot encoding for categoricals\n",
    "# ---------------------------------\n",
    "encoded = pd.get_dummies(data, columns=[\"region\", \"device_type\"], drop_first=True, dtype=int)\n",
    "print(\"\\n[Encoded columns added]:\", [c for c in encoded.columns if c.startswith(\"region_\") or c.startswith(\"device_type_\")])\n",
    "\n",
    "# ---------------------------------\n",
    "# 4) Prune redundancy (keep one per highly correlated pair)\n",
    "#    Decisions (guided by your correlation table):\n",
    "#    - Keep the transformed versions + ratio-type signals.\n",
    "#    - Drop raw counts / twin indices and one of the text length pair.\n",
    "# ---------------------------------\n",
    "drop_cols = [\n",
    "    # keep likes_score_log + vote_ratio; drop raw twins\n",
    "    \"likes\", \"likes_score\",\n",
    "    # keep dislike_index_log; drop raw twin\n",
    "    \"dislikes\", \"dislike_index\",\n",
    "    # keep response_level; drop raw twin count\n",
    "    \"responses\",\n",
    "    # keep user_index; drop its twin\n",
    "    \"user_score\",\n",
    "    # keep ranking_value; drop twin\n",
    "    \"ranking_score\",\n",
    "    # text: keep word_count; drop text_len (r≈0.995)\n",
    "    \"text_len\",\n",
    "]\n",
    "\n",
    "encoded = encoded.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "kept_example = [\"likes_score_log\", \"dislike_index_log\", \"vote_ratio\",\n",
    "                \"response_level\", \"user_index\", \"ranking_value\", \"word_count\"]\n",
    "print(\"\\n[Kept representative signals]:\", kept_example)\n",
    "\n",
    "# (Optional sanity) check again extreme correlations (>0.95)\n",
    "corr = encoded.corr(numeric_only=True)\n",
    "high_again = [(a,b,float(corr.loc[a,b]))\n",
    "              for a in corr.columns for b in corr.columns\n",
    "              if a<b and abs(corr.loc[a,b])>0.95 and a!=\"stars\" and b!=\"stars\"]\n",
    "print(\"\\n[High correlations > 0.95 AFTER pruning]:\")\n",
    "print(high_again if high_again else \"None detected\")\n",
    "\n",
    "# ---------------------------------\n",
    "# 5) Final dataset for modeling\n",
    "# ---------------------------------\n",
    "# We will NOT model raw text now (no advanced NLP), only the simple text features created.\n",
    "# So we keep 'text' for documentation, but exclude it from X later.\n",
    "df_model = encoded.copy()\n",
    "\n",
    "print(\"\\n[Shape BEFORE FE]:\", df.shape)\n",
    "print(\"[Shape AFTER FE ]:\", df_model.shape)\n",
    "\n",
    "# quick head\n",
    "display(df_model.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390e722",
   "metadata": {},
   "source": [
    "### Observations – Block 4 (Feature Engineering)\n",
    "\n",
    "Feature engineering was guided directly by the EDA findings.  \n",
    "Log transformation of `likes_score` and `dislike_index` reduced skewness, making these features less dominated by outliers.  \n",
    "\n",
    "One-hot encoding was applied to `region` and `device_type`, ensuring categorical information could be captured by models.  \n",
    "Highly correlated variables were pruned to avoid redundancy, reducing risk of multicollinearity.  \n",
    "\n",
    "The resulting feature set is cleaner, more stable, and better suited for predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0731cb",
   "metadata": {},
   "source": [
    "### Refinement of Feature Engineering  \n",
    "\n",
    "Although the initial feature engineering step produced a dataset with 27 variables, further inspection revealed strong collinearity among several pairs (e.g., `likes_score` vs. `likes`, `dislike_index` vs. `dislikes`, `user_index` vs. `user_score`). Keeping both versions of such features could lead to redundancy and instability during model training.  \n",
    "\n",
    "To address this, I refined the feature set by retaining only the representative signals (log-transformed versions, ratios, and normalized indexes) and removing duplicates. I also added `exclam_cnt` as a lightweight proxy for sentiment emphasis.  \n",
    "\n",
    "As a result, the dataset was reduced to 20 features, eliminating correlations above 0.95 while preserving interpretability and predictive power. This refinement step ensures a cleaner and more robust dataset for the modeling stage.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a487e",
   "metadata": {},
   "source": [
    "## Block 5 – Model Building\n",
    "\n",
    "**From the instructions:**  \n",
    "- *“Build appropriate models, document the process, and tune for performance.”*  \n",
    "\n",
    "**Steps in this block:**  \n",
    "1. Split the dataset into training and test sets (stratified by `stars`).  \n",
    "2. Train a baseline **Logistic Regression** model.  \n",
    "3. Train a **Random Forest** classifier as a more powerful model.  \n",
    "4. Evaluate models with multiple metrics: accuracy, precision, recall, F1 (macro).  \n",
    "5. Show confusion matrices to visualize errors.  \n",
    "6. Discuss results and model selection.  \n",
    "\n",
    "The goal is to compare a simple baseline with a more complex tree-based model, and assess which better captures the patterns in the data while handling the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Block 5 – Model Building\n",
    "# =============================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,   # <-- added for explicit Accuracy\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------\n",
    "# 1) Prepare X and y\n",
    "# ---------------------------------\n",
    "X = df_model.drop(columns=[\"stars\", \"text\", \"recipe_name\", \"created_at\"])\n",
    "y = df_model[\"stars\"]\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"[Info] Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "print(\"[Distribution Train]\", y_train.value_counts(normalize=True).round(3))\n",
    "print(\"[Distribution Test ]\", y_test.value_counts(normalize=True).round(3))\n",
    "\n",
    "# ---------------------------------\n",
    "# 2) Baseline Logistic Regression\n",
    "# ---------------------------------\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", multi_class=\"multinomial\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"\\n[Logistic Regression Results]\")\n",
    "print(f\"Accuracy (LogReg): {accuracy_score(y_test, y_pred_lr):.4f}\")  # <-- explicit accuracy\n",
    "print(classification_report(y_test, y_pred_lr, digits=3))\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "ConfusionMatrixDisplay(cm_lr).plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.tight_layout()  # <-- better spacing\n",
    "plt.savefig(\"outputs/confusion_matrix_logistic_regression.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------\n",
    "# 3) Random Forest Classifier\n",
    "# ---------------------------------\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n[Random Forest Results]\")\n",
    "print(f\"Accuracy (RF): {accuracy_score(y_test, y_pred_rf):.4f}\")       # <-- explicit accuracy\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "ConfusionMatrixDisplay(cm_rf).plot(cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix – Random Forest\")\n",
    "plt.tight_layout()  # <-- better spacing\n",
    "plt.savefig(\"outputs/confusion_matrix_random_forest.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c723d23",
   "metadata": {},
   "source": [
    "#### Small hyperparameter search (kept short on purpose)\n",
    "\n",
    "I ran a small grid over depth, estimators, and min_samples_split.  \n",
    "**Best params (RF)**: `{'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}`.  \n",
    "On the hold-out test set the tuned model reached **Accuracy = 0.759**. This is roughly on par with the baseline RF (0.763) and did not improve it—which can happen with small grids and limited signal. I kept the tuned version for the next section to compute feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Random Forest — small grid search (short on purpose) ---\n",
    "rf_var = None\n",
    "for name in [\"best_rf\", \"rf_clf\", \"rf\", \"clf\"]:\n",
    "    if name in globals():\n",
    "        rf_var = globals()[name]\n",
    "        break\n",
    "\n",
    "if rf_var is None or \"X_train\" not in globals() or \"y_train\" not in globals():\n",
    "    print(\"[note] RF grid search skipped (need rf_clf/best_rf and X_train/y_train).\")\n",
    "else:\n",
    "    # handle Pipeline vs bare estimator\n",
    "    is_pipeline = hasattr(rf_var, \"steps\")\n",
    "    p_n = \"rf__n_estimators\" if is_pipeline else \"n_estimators\"\n",
    "    p_d = \"rf__max_depth\"     if is_pipeline else \"max_depth\"\n",
    "    p_s = \"rf__min_samples_split\" if is_pipeline else \"min_samples_split\"\n",
    "\n",
    "    rf_param_grid = {\n",
    "        p_n: [100, 200],\n",
    "        p_d: [None, 10, 20],\n",
    "        p_s: [2, 5],\n",
    "    }\n",
    "\n",
    "    rf_gs = GridSearchCV(\n",
    "        rf_var, rf_param_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=0\n",
    "    )\n",
    "    rf_gs.fit(X_train, y_train)\n",
    "    best_rf = rf_gs.best_estimator_\n",
    "    print(\"Best params (RF):\", rf_gs.best_params_)\n",
    "\n",
    "    # ---- Evaluate tuned model on hold-out test ----\n",
    "    y_pred_rf_tuned = best_rf.predict(X_test)\n",
    "    print(f\"Accuracy (RF tuned): {accuracy_score(y_test, y_pred_rf_tuned):.4f}\")\n",
    "    print(classification_report(y_test, y_pred_rf_tuned, digits=3))\n",
    "\n",
    "    # Confusion matrix (tuned)\n",
    "    cm_rf = confusion_matrix(y_test, y_pred_rf_tuned)\n",
    "    ConfusionMatrixDisplay(cm_rf).plot(cmap=\"Greens\")\n",
    "    plt.title(\"Confusion Matrix – Random Forest (tuned)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/confusion_matrix_random_forest_tuned.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "    # ROC curve (only if binary)\n",
    "    if hasattr(best_rf, \"predict_proba\"):\n",
    "        proba = best_rf.predict_proba(X_test)\n",
    "        if proba.shape[1] == 2:\n",
    "            fpr, tpr, _ = roc_curve(y_test, proba[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure(figsize=(5.5, 4.5))\n",
    "            plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "            plt.plot([0, 1], [0, 1], \"--\")\n",
    "            plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC – Random Forest (tuned)\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"outputs/roc_curve_random_forest_tuned.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"[note] Multiclass ROC not shown—sticking to CM + macro metrics for clarity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44756b",
   "metadata": {},
   "source": [
    "## Feature Importance (short and readable)\n",
    "I computed MDI feature importance using the tuned Random Forest. This is a quick way to see what the model leaned on the most; it’s useful for intuition, but correlated features can split importance. I limited the plot to the Top-12 so it’s readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# If a tuned RF pipeline (best_rf) exists, use it. Otherwise, build a small one from df.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 1) try to reuse an already-fitted pipeline (prefer my tuned RF)\n",
    "pipe = None\n",
    "source = None\n",
    "if 'best_rf' in globals():\n",
    "    pipe, source = best_rf, \"best_rf\"\n",
    "elif 'rf_gs' in globals():\n",
    "    try:\n",
    "        pipe, source = rf_gs.best_estimator_, \"rf_gs.best_estimator_\"\n",
    "    except Exception:\n",
    "        pass\n",
    "elif 'rf_clf' in globals():\n",
    "    pipe, source = rf_clf, \"rf_clf\"\n",
    "\n",
    "# 2) if nothing exists, build a small RF pipeline from df so this cell still works\n",
    "if pipe is None:\n",
    "    # make sure df exists (load from same folder if needed)\n",
    "    if 'df' not in globals():\n",
    "        df = pd.read_csv(\"data/recipe_reviews.csv\")\n",
    "\n",
    "    # infer the target column used in this course\n",
    "    target_candidates = [\"stars\", \"star_rating\", \"rating\", \"target\"]\n",
    "    target_col = next((c for c in target_candidates if c in df.columns), None)\n",
    "    if target_col is None:\n",
    "        raise RuntimeError(\"Couldn't infer the target column. Set target_col to your label (e.g., 'stars').\")\n",
    "\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col])\n",
    "\n",
    "    # basic lists for preprocessing\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), num_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, stratify=y if getattr(y, \"nunique\", lambda: 0)() > 1 else None, random_state=42\n",
    "    )\n",
    "\n",
    "    # small RF so it runs fast but gives a reasonable importance picture\n",
    "    pipe = Pipeline([\n",
    "        ('prep', preprocess),\n",
    "        ('rf', RandomForestClassifier(random_state=42, n_estimators=50, max_depth=10))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    source = \"ad-hoc RF (built here so the plot doesn't break)\"\n",
    "\n",
    "# 3) recover readable feature names from the ColumnTransformer (numeric + one-hot)\n",
    "feature_names = []\n",
    "try:\n",
    "    ct = pipe.named_steps['prep']\n",
    "    # try to find the numeric and categorical pieces regardless of the alias\n",
    "    num_cols = None; cat_cols = None; ohe = None\n",
    "    for name, tr, cols in ct.transformers_:\n",
    "        # heuristic: StandardScaler in numeric branch; OneHotEncoder in categorical\n",
    "        if hasattr(tr, \"mean_\") or name in (\"num\", \"numeric\"):\n",
    "            num_cols = cols\n",
    "        if \"OneHotEncoder\" in tr.__class__.__name__ or name in (\"cat\", \"categorical\"):\n",
    "            cat_cols = cols; ohe = tr\n",
    "    ohe_names = list(ohe.get_feature_names_out(cat_cols)) if ohe is not None else []\n",
    "    feature_names = list(num_cols or []) + ohe_names\n",
    "except Exception:\n",
    "    feature_names = []\n",
    "\n",
    "# 4) get importance values in this order: RF MDI -> |coef| -> permutation\n",
    "importances = None\n",
    "kind = \"\"\n",
    "rf_step = pipe.named_steps.get('rf', None) if hasattr(pipe, \"named_steps\") else None\n",
    "clf_step = pipe.named_steps.get('clf', None) if hasattr(pipe, \"named_steps\") else None\n",
    "\n",
    "if rf_step is not None and hasattr(rf_step, \"feature_importances_\"):\n",
    "    importances = rf_step.feature_importances_\n",
    "    kind = \"RandomForest MDI\"\n",
    "elif clf_step is not None and hasattr(clf_step, \"coef_\"):\n",
    "    importances = np.abs(clf_step.coef_).ravel()\n",
    "    kind = \"|coef|\"\n",
    "else:\n",
    "    # last resort: permutation (needs X_test / y_test)\n",
    "    if 'X_test' in globals() and 'y_test' in globals():\n",
    "        r = permutation_importance(pipe, X_test, y_test, n_repeats=5, random_state=42, n_jobs=-1)\n",
    "        importances = r.importances_mean\n",
    "        kind = \"permutation\"\n",
    "    else:\n",
    "        raise RuntimeError(\"No importances available (need RF/coef or X_test/y_test for permutation).\")\n",
    "\n",
    "# align names length or fallback\n",
    "if not feature_names or len(feature_names) != len(importances):\n",
    "    feature_names = [f\"f{i}\" for i in range(len(importances))]\n",
    "\n",
    "# 5) plot top-12 and export\n",
    "idx = np.argsort(importances)[::-1][:12]\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "bars = plt.barh(range(len(idx)), importances[idx])\n",
    "plt.yticks(range(len(idx)), np.array(feature_names)[idx])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance — Top 12\")\n",
    "plt.xlabel(f\"Importance ({kind}, higher = more influence)\")\n",
    "plt.ylabel(\"Feature (numeric + one-hot categories)\")\n",
    "try:\n",
    "    plt.bar_label(bars, fmt=\"%.3f\", padding=3)   # readable values\n",
    "except Exception:\n",
    "    pass\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/feature_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624259e8",
   "metadata": {},
   "source": [
    "### Observations – Block 5 (Model Building)\n",
    "\n",
    "Quick takeaways:\n",
    "- **Logistic Regression** underperformed on this dataset (**Accuracy ≈ 0.318**), which fits the intuition: the decision boundaries are not linearly separable and we have many one-hot columns.\n",
    "- **Random Forest (baseline)** did much better (**Accuracy ≈ 0.763**).\n",
    "- The **tuned RF** via a short grid was **≈ 0.759**, very close but not higher than the baseline. With a larger search or different seeds we might squeeze a bit more, but I kept things intentionally short and reproducible.\n",
    "- Confusion matrices show most mistakes in the middle classes (2–3 stars), which is common when the distribution skews toward 4–5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d52aa76",
   "metadata": {},
   "source": [
    "### Observations – Block 6 (Balancing)\n",
    "\n",
    "Two quick imbalance strategies:\n",
    "- **Logistic Regression with class weights** came out at **Accuracy ≈ 0.318**, basically the same as the baseline LogReg.\n",
    "- **Random Forest with SMOTE** reduced overall accuracy to **≈ 0.672**. That’s a typical trade-off: oversampling can help minority coverage/recall, but it often costs accuracy.\n",
    "\n",
    "For ROC/AUC I show a one-vs-rest curve focused on **5-star** reviews to keep the plot readable. In a longer version I’d add macro OVR curves for all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Block 6 – Advanced Evaluation and Class Balancing\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve, accuracy_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"[Block 6] Starting advanced evaluation with class balancing...\")\n",
    "\n",
    "# -------------------------------\n",
    "# Logistic Regression (class weights)\n",
    "# -------------------------------\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "print(\"[Class Weights]\", class_weight_dict)\n",
    "\n",
    "log_reg_bal = LogisticRegression(\n",
    "    max_iter=1000, class_weight=class_weight_dict, solver=\"lbfgs\", multi_class=\"multinomial\"\n",
    ")\n",
    "log_reg_bal.fit(X_train, y_train)\n",
    "y_pred_log_bal = log_reg_bal.predict(X_test)\n",
    "\n",
    "print(\"\\n[Logistic Regression (balanced) Results]\")\n",
    "print(f\"Accuracy (LogReg balanced): {accuracy_score(y_test, y_pred_log_bal):.4f}\")\n",
    "print(classification_report(y_test, y_pred_log_bal, digits=3))\n",
    "\n",
    "# -------------------------------\n",
    "# Random Forest with SMOTE (train only)\n",
    "# -------------------------------\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"[SMOTE] Resampled training set shape:\", X_train_res.shape, y_train_res.shape)\n",
    "\n",
    "print(\"[INFO] Training light RF for reproducibility (GitHub-safe)\")\n",
    "rf_bal = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=10)\n",
    "rf_bal.fit(X_train_res, y_train_res)\n",
    "y_pred_rf_bal = rf_bal.predict(X_test)\n",
    "\n",
    "print(\"\\n[Random Forest (SMOTE) Results]\")\n",
    "print(f\"Accuracy (RF SMOTE): {accuracy_score(y_test, y_pred_rf_bal):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf_bal, digits=3))\n",
    "\n",
    "# -------------------------------\n",
    "# Confusion matrices (side by side)\n",
    "# -------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log_bal, ax=axes[0], cmap=\"Blues\")\n",
    "axes[0].set_title(\"Confusion Matrix – Logistic Regression (Balanced)\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf_bal, ax=axes[1], cmap=\"Greens\")\n",
    "axes[1].set_title(\"Confusion Matrix – Random Forest (SMOTE)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/confusion_matrices_balanced.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# ROC curve — one-vs-rest for 5 stars\n",
    "# -------------------------------\n",
    "if hasattr(rf_bal, \"predict_proba\"):\n",
    "    y_test_bin = (y_test == 5).astype(int)\n",
    "    proba_rf = rf_bal.predict_proba(X_test)\n",
    "    # find index of class '5' robustly\n",
    "    cls_idx = list(rf_bal.classes_).index(5) if 5 in rf_bal.classes_ else None\n",
    "    if cls_idx is not None:\n",
    "        y_score_rf = proba_rf[:, cls_idx]\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin, y_score_rf)\n",
    "        roc_auc = roc_auc_score(y_test_bin, y_score_rf)\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.plot(fpr, tpr, label=f\"RF (SMOTE) AUC = {roc_auc:.2f}\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC — Predicting 5 Stars vs Rest\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"roc_curve_random_forest_5stars.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"[note] Class '5' not found in rf_bal.classes_; skipping the 5-star ROC.\")\n",
    "else:\n",
    "    print(\"[note] rf_bal has no predict_proba; skipping ROC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd98a3",
   "metadata": {},
   "source": [
    "## Executive Summary (Final Report & Business Conclusions)\n",
    "\n",
    "**What worked best.** The **Random Forest (baseline)** was the top performer on the hold-out set (**Accuracy ≈ 0.763**). A short grid search produced a tuned RF (**≈ 0.759**), which was roughly on par but did not surpass the baseline. Logistic Regression lagged (**≈ 0.318**), which matches the idea that non-linear patterns dominate here.\n",
    "\n",
    "**Why this matters.** Even with modest tuning, tree-based models handle sparse one-hot features and non-linearities better in this dataset. The feature-importance view is helpful to communicate what the model pays attention to, though I’d validate the top signals with permutation importance if I had more time.\n",
    "\n",
    "**Imbalance.** Ratings skew toward higher values, so the middle classes (2–3 stars) are harder to predict consistently. Class weighting didn’t change LogReg much; SMOTE helped rebalance the training set but reduced overall accuracy, which is a common trade-off.\n",
    "\n",
    "**Next steps.** If this were a production project I’d (a) expand the hyperparameter search (depth, leaves, min_samples), (b) test calibrated probabilities and macro-OVR curves for all classes, and (c) iterate on feature engineering (e.g., richer text signals, interactions) to target the hard middle classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
